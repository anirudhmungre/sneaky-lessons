{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BtCOyQ3kChJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.3'\n",
    "spark_version = 'spark-3.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3FP8HaLokHui"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CloudETLProjectAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "9LSw6QzzkMkY",
    "outputId": "8309bb4b-56fb-4fc8-e228-07c88b19d87d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "|    coffee_shop_name|         review_text|           rating|num_rating|cat_rating|bool_HIGH|overall_sent|vibe_sent|tea_sent|service_sent|seating_sent|price_sent|parking_sent|location_sent|alcohol_sent|coffee_sent|food_sent|hours_sent|internet_sent|local_sent|\n",
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "|The Factory - Caf...|11/25/2016 1 chec...| 5.0 star rating |         5|      HIGH|        1|           4|        3|       0|           0|           0|         0|           0|            0|           1|          3|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|12/2/2016 Listed ...| 4.0 star rating |         4|      HIGH|        1|           3|        3|       0|           0|           0|         0|           0|            0|           0|          0|        2|         0|            0|         0|\n",
      "|The Factory - Caf...|11/30/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           2|        2|       0|           0|           3|         0|           0|            0|           0|         -1|        2|         0|            0|         0|\n",
      "|The Factory - Caf...|11/25/2016 Very c...| 2.0 star rating |         2|       LOW|        0|           1|        0|       0|           0|          -1|        -1|           0|            0|           0|          0|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|12/3/2016 1 check...| 4.0 star rating |         4|      HIGH|        1|           2|        0|       0|           0|           0|         0|           3|            0|           0|          0|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|11/20/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           0|        2|       0|           0|           0|        -2|           0|            0|           0|          0|        0|         0|           -1|         0|\n",
      "|The Factory - Caf...|\"10/27/2016 2 che...| 4.0 star rating |         4|      HIGH|        1|           3|        0|       0|           0|           2|         0|           0|            0|           0|          1|        1|         1|            0|         0|\n",
      "|The Factory - Caf...|\"11/2/2016 2 chec...| 5.0 star rating |         5|      HIGH|        1|           0|        1|       0|           1|          -1|         0|           1|            1|           0|         -1|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|\"10/25/2016 1 che...| 3.0 star rating |         3|       LOW|        0|           3|        3|       0|           0|           0|         1|           0|            0|           0|          0|        2|         0|            1|         0|\n",
      "|The Factory - Caf...|11/10/2016 3 chec...| 5.0 star rating |         5|      HIGH|        1|           3|        1|       0|           0|           0|         0|           0|            0|           0|          1|        0|         0|            0|         0|\n",
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "# Load in user_data.csv from S3 into a DataFrame\n",
    "url = \"https://s3.amazonaws.com//dataviz-curriculum/day_3/ratings_and_sentiments.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "df = spark.read.option('header', 'true').csv(SparkFiles.get(\"ratings_and_sentiments.csv\"), inferSchema=True, sep=',', timestampFormat=\"mm/dd/yy\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IifpzN6zkN5Q"
   },
   "source": [
    "## Transform DataFrame to fit coffe_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "E72hLCa7kT_D",
    "outputId": "0f4ca389-1f47-4821-f818-627dd7c11778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|    coffee_shop_name|num_rating|\n",
      "+--------------------+----------+\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         2|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         3|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         3|\n",
      "|The Factory - Caf...|         3|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         5|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         4|\n",
      "|The Factory - Caf...|         4|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shop_df = df.select([\"coffee_shop_name\",\"num_rating\"])\n",
    "shop_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "kRvAVaeWkXXn",
    "outputId": "f6700c75-ad3b-4bac-f343-b2635370c4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+------------------+\n",
      "|    coffee_shop_name|count(coffee_shop_name)|   avg(num_rating)|\n",
      "+--------------------+-----------------------+------------------+\n",
      "|      Flitch Coffee |                     28| 4.821428571428571|\n",
      "|Apanas Coffee & B...|                    136| 4.580882352941177|\n",
      "|Arturo's Undergro...|                    100|               4.3|\n",
      "|Lola Savannah Cof...|                      4|               5.0|\n",
      "|Lola Savannah Cof...|                    100|              4.11|\n",
      "|       Epoch Coffee |                    400|            3.8125|\n",
      "|       Caffe Medici |                    243|4.1193415637860085|\n",
      "|Figure 8 Coffee P...|                    100|               4.5|\n",
      "|    Hot Mama's Cafe |                    100|              4.27|\n",
      "|  Sorrento's Coffee |                    100|              4.26|\n",
      "|  The Steeping Room |                    100|              3.96|\n",
      "|Irie Bean Coffee ...|                    100|               4.3|\n",
      "| Thunderbird Coffee |                    100|              3.97|\n",
      "|Flightpath Coffee...|                    100|              4.23|\n",
      "|     Tuscany At 360 |                     33|3.8181818181818183|\n",
      "|            Halcyon |                    300|              3.82|\n",
      "|Summer Moon Coffe...|                    100|              4.09|\n",
      "|     Trianon Coffee |                     98| 4.020408163265306|\n",
      "|Summermoon Coffee...|                    100|              4.53|\n",
      "|             Cenote |                    100|              4.04|\n",
      "+--------------------+-----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coffee_ratings_df = shop_df.groupby(\"coffee_shop_name\").agg({\"num_rating\": \"avg\", \"coffee_shop_name\":\"count\"})\n",
    "coffee_ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "OJgQqozHkYhz",
    "outputId": "8c0d6b3d-4118-49ac-c199-5cb61cee86f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------------+\n",
      "|    coffee_shop_name|total_ratings|       avg_rating|\n",
      "+--------------------+-------------+-----------------+\n",
      "|Lola Savannah Cof...|            4|              5.0|\n",
      "|The Marvelous Vin...|           10|              5.0|\n",
      "|Ma√±ana Coffee & J...|           33|4.848484848484849|\n",
      "|       Brian's Brew |           45|4.844444444444444|\n",
      "|Third Coast Coffe...|           56|4.821428571428571|\n",
      "|      Flitch Coffee |           28|4.821428571428571|\n",
      "|   Kowabunga Coffee |           16|           4.8125|\n",
      "|Venezia Italian G...|          200|             4.81|\n",
      "|      Legend Coffee |           28|4.714285714285714|\n",
      "|       Fleet Coffee |           57|4.701754385964913|\n",
      "|    My Sweet Austin |           31| 4.67741935483871|\n",
      "|         Dolce Neve |          100|             4.64|\n",
      "|       Holy Grounds |           30|4.633333333333334|\n",
      "|Anderson's Coffee...|          100|             4.62|\n",
      "|Apanas Coffee & B...|          136|4.580882352941177|\n",
      "|  Flat Track Coffee |           63|4.571428571428571|\n",
      "|Friends & Neighbors |           29|4.551724137931035|\n",
      "|Summermoon Coffee...|          100|             4.53|\n",
      "|      Corona Coffee |          100|             4.53|\n",
      "|    Live Oak Market |          100|             4.51|\n",
      "+--------------------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "coffee_ratings_df = coffee_ratings_df.withColumnRenamed(\"count(coffee_shop_name)\", \"total_ratings\")\\\n",
    "                                     .withColumnRenamed(\"avg(num_rating)\", \"avg_rating\")\n",
    "coffee_ratings_df.orderBy(desc(\"avg_rating\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnF65nZ1kZAi"
   },
   "source": [
    "## Transform DataFrame to fit date_table table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8gR8zpukhqW"
   },
   "outputs": [],
   "source": [
    "review_df = df.select([\"review_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "iuV6hvV6kkcU",
    "outputId": "646523af-9216-4048-d382-9656ad796579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      date|         review_text|\n",
      "+----------+--------------------+\n",
      "|11/25/2016|1 check-in Love l...|\n",
      "| 12/2/2016|Listed in Date Ni...|\n",
      "|11/30/2016|1 check-in Listed...|\n",
      "|11/25/2016|Very cool vibe! G...|\n",
      "| 12/3/2016|1 check-in They a...|\n",
      "|11/20/2016|1 check-in Very c...|\n",
      "|10/27/2016|2 check-ins Liste...|\n",
      "| 11/2/2016|2 check-ins Love ...|\n",
      "|10/25/2016|1 check-in Ok let...|\n",
      "|11/10/2016|3 check-ins This ...|\n",
      "|10/22/2016|1 check-in Listed...|\n",
      "|11/20/2016|The store has A+ ...|\n",
      "|11/17/2016|1 check-in Listed...|\n",
      "| 12/5/2016|This is such a cu...|\n",
      "|11/13/2016|Beautiful eccentr...|\n",
      "| 11/9/2016|1 check-in Listed...|\n",
      "| 11/6/2016|Really love the v...|\n",
      "|10/25/2016|1 check-in Check ...|\n",
      "|10/15/2016|1 check-in Note: ...|\n",
      "| 12/1/2016|So much aesthetic...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "review_df = review_df.withColumn(\"date\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+\", 0))\\\n",
    "      .withColumn(\"review_text\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+(?:\\s)(.*)\", 1))\\\n",
    "      .select([\"date\", \"review_text\"])\\\n",
    "      .dropna()\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "nVPFb0PzkkTH",
    "outputId": "a5134e88-4f1c-4f67-827d-5590007af543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      date|review_count|\n",
      "+----------+------------+\n",
      "| 8/21/2016|          16|\n",
      "| 6/29/2016|          10|\n",
      "| 8/19/2013|           2|\n",
      "| 2/27/2015|           5|\n",
      "| 7/31/2016|          13|\n",
      "| 3/17/2014|           7|\n",
      "|11/14/2015|          11|\n",
      "| 6/10/2011|           1|\n",
      "|10/10/2009|           1|\n",
      "| 4/27/2014|           1|\n",
      "| 3/27/2009|           1|\n",
      "| 12/8/2011|           1|\n",
      "| 2/21/2014|           2|\n",
      "| 8/31/2015|          10|\n",
      "| 1/15/2015|           3|\n",
      "| 3/16/2012|           1|\n",
      "|  8/9/2016|           4|\n",
      "|11/24/2016|           1|\n",
      "|  8/2/2014|           5|\n",
      "| 3/23/2011|           1|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_df = review_df.groupBy('date').agg({\"date\": \"count\"})\n",
    "date_df = date_df.withColumnRenamed(\"count(date)\", \"review_count\")\n",
    "date_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "E6P2i7rCkjte",
    "outputId": "e0235c48-5dd4-4771-e204-5ed56bbd807a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|      date|review_count|\n",
      "+----------+------------+\n",
      "| 10/9/2016|          31|\n",
      "| 9/18/2016|          30|\n",
      "|11/20/2016|          27|\n",
      "| 11/2/2016|          27|\n",
      "| 12/2/2016|          26|\n",
      "| 12/4/2016|          26|\n",
      "| 9/15/2016|          25|\n",
      "| 10/7/2016|          24|\n",
      "| 11/6/2016|          24|\n",
      "| 7/24/2016|          24|\n",
      "| 4/17/2016|          23|\n",
      "|10/25/2016|          23|\n",
      "| 12/3/2016|          23|\n",
      "| 12/1/2016|          23|\n",
      "|  8/7/2016|          22|\n",
      "| 6/27/2016|          22|\n",
      "|  1/4/2016|          21|\n",
      "| 1/17/2016|          21|\n",
      "|11/21/2016|          21|\n",
      "| 8/13/2016|          20|\n",
      "+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_df.orderBy(desc(\"review_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXQe3s_ElN2U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cloud_etl_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
