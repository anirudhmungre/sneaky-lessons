{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKHacoX0qc-u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.3'\n",
    "spark_version = 'spark-3.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hb1lwcPJqV_y"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ogdI6RYKqV_6",
    "outputId": "acf6fa7c-40b9-4d81-f239-68c3ab613db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|               words|\n",
      "+---+--------------------+\n",
      "|  0|The cow cow jumpe...|\n",
      "|  1|   then the cow said|\n",
      "|  2|I am a cow that j...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame with repeating words\n",
    "dataframe = spark.createDataFrame([\n",
    "    (0, \"The cow cow jumped and jumped cow\"),\n",
    "    (1, \"then the cow said\"),\n",
    "    (2, \"I am a cow that jumped\")\n",
    "],[\"id\", \"words\"])\n",
    "\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "3HSZu5z2qWAA",
    "outputId": "5e00ab35-0c32-4cd9-c27d-e658c5cf3232"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               words|              tokens|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|The cow cow jumpe...|[the, cow, cow, j...|\n",
      "|  1|   then the cow said|[then, the, cow, ...|\n",
      "|  2|I am a cow that j...|[i, am, a, cow, t...|\n",
      "+---+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the words\n",
    "tokenizer = Tokenizer(inputCol=\"words\", outputCol=\"tokens\")\n",
    "wordsData = tokenizer.transform(dataframe)\n",
    "wordsData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOB8cgOzqWAE"
   },
   "outputs": [],
   "source": [
    "# Run the hashing term frequency\n",
    "hashing = HashingTF(inputCol=\"tokens\", outputCol=\"hashedValues\", numFeatures=pow(2,4))\n",
    "\n",
    "# Transform into a DF\n",
    "hashed_df = hashing.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "mw-AwFDTqWAJ",
    "outputId": "ef43f689-e8d0-438f-b096-062bad3df07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------+-----------------------------------------+----------------------------------------------+\n",
      "|id |words                            |tokens                                   |hashedValues                                  |\n",
      "+---+---------------------------------+-----------------------------------------+----------------------------------------------+\n",
      "|0  |The cow cow jumped and jumped cow|[the, cow, cow, jumped, and, jumped, cow]|(16,[11,13,14,15],[2.0,1.0,1.0,3.0])          |\n",
      "|1  |then the cow said                |[then, the, cow, said]                   |(16,[0,13,14,15],[1.0,1.0,1.0,1.0])           |\n",
      "|2  |I am a cow that jumped           |[i, am, a, cow, that, jumped]            |(16,[0,1,2,5,11,15],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+---+---------------------------------+-----------------------------------------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display new DataFrame\n",
    "hashed_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWCmi9EXqWAO"
   },
   "outputs": [],
   "source": [
    "# Fit the IDF on the data set \n",
    "idf = IDF(inputCol=\"hashedValues\", outputCol=\"features\")\n",
    "idfModel = idf.fit(hashed_df)\n",
    "rescaledData = idfModel.transform(hashed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "j73AlD-SqWAW",
    "outputId": "9eae163b-c38f-4564-b92d-0da159260e10"
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "rescaledData.select(\"tokens\", \"features\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nlp_hashingTF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
