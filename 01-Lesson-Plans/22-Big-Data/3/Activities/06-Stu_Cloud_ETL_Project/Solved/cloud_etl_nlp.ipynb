{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV4ajtm-iijA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.3'\n",
    "spark_version = 'spark-3.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21VIzGHIioxp"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CloudETLProject\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "vGQc0BlXit96",
    "outputId": "b162d077-2a7e-42e5-bb0c-383c2a9e3786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "|    coffee_shop_name|         review_text|           rating|num_rating|cat_rating|bool_HIGH|overall_sent|vibe_sent|tea_sent|service_sent|seating_sent|price_sent|parking_sent|location_sent|alcohol_sent|coffee_sent|food_sent|hours_sent|internet_sent|local_sent|\n",
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "|The Factory - Caf...|11/25/2016 1 chec...| 5.0 star rating |         5|      HIGH|        1|           4|        3|       0|           0|           0|         0|           0|            0|           1|          3|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|12/2/2016 Listed ...| 4.0 star rating |         4|      HIGH|        1|           3|        3|       0|           0|           0|         0|           0|            0|           0|          0|        2|         0|            0|         0|\n",
      "|The Factory - Caf...|11/30/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           2|        2|       0|           0|           3|         0|           0|            0|           0|         -1|        2|         0|            0|         0|\n",
      "|The Factory - Caf...|11/25/2016 Very c...| 2.0 star rating |         2|       LOW|        0|           1|        0|       0|           0|          -1|        -1|           0|            0|           0|          0|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|12/3/2016 1 check...| 4.0 star rating |         4|      HIGH|        1|           2|        0|       0|           0|           0|         0|           3|            0|           0|          0|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|11/20/2016 1 chec...| 4.0 star rating |         4|      HIGH|        1|           0|        2|       0|           0|           0|        -2|           0|            0|           0|          0|        0|         0|           -1|         0|\n",
      "|The Factory - Caf...|\"10/27/2016 2 che...| 4.0 star rating |         4|      HIGH|        1|           3|        0|       0|           0|           2|         0|           0|            0|           0|          1|        1|         1|            0|         0|\n",
      "|The Factory - Caf...|\"11/2/2016 2 chec...| 5.0 star rating |         5|      HIGH|        1|           0|        1|       0|           1|          -1|         0|           1|            1|           0|         -1|        0|         0|            0|         0|\n",
      "|The Factory - Caf...|\"10/25/2016 1 che...| 3.0 star rating |         3|       LOW|        0|           3|        3|       0|           0|           0|         1|           0|            0|           0|          0|        2|         0|            1|         0|\n",
      "|The Factory - Caf...|11/10/2016 3 chec...| 5.0 star rating |         5|      HIGH|        1|           3|        1|       0|           0|           0|         0|           0|            0|           0|          1|        0|         0|            0|         0|\n",
      "+--------------------+--------------------+-----------------+----------+----------+---------+------------+---------+--------+------------+------------+----------+------------+-------------+------------+-----------+---------+----------+-------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "# Load in user_data.csv from S3 into a DataFrame\n",
    "url = \"https://s3.amazonaws.com//dataviz-curriculum/day_3/ratings_and_sentiments.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "df = spark.read.option('header', 'true').csv(SparkFiles.get(\"ratings_and_sentiments.csv\"), inferSchema=True, sep=',', timestampFormat=\"mm/dd/yy\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHrs8Uk1i0RX"
   },
   "source": [
    "## Transform DataFrame to fit review_rating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "KvpPZ1TEiwyu",
    "outputId": "b195157c-c6e4-4690-dc2d-7e506d290765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|         review_text|num_rating|\n",
      "+--------------------+----------+\n",
      "|11/25/2016 1 chec...|         5|\n",
      "|12/2/2016 Listed ...|         4|\n",
      "|11/30/2016 1 chec...|         4|\n",
      "|11/25/2016 Very c...|         2|\n",
      "|12/3/2016 1 check...|         4|\n",
      "|11/20/2016 1 chec...|         4|\n",
      "|\"10/27/2016 2 che...|         4|\n",
      "|\"11/2/2016 2 chec...|         5|\n",
      "|\"10/25/2016 1 che...|         3|\n",
      "|11/10/2016 3 chec...|         5|\n",
      "|\"10/22/2016 1 che...|         4|\n",
      "|11/20/2016 The st...|         3|\n",
      "|11/17/2016 1 chec...|         3|\n",
      "|12/5/2016 This is...|         5|\n",
      "|11/13/2016 Beauti...|         5|\n",
      "|11/9/2016 1 check...|         5|\n",
      "|11/6/2016 Really ...|         5|\n",
      "|10/25/2016 1 chec...|         4|\n",
      "|10/15/2016 1 chec...|         4|\n",
      "|12/1/2016 So much...|         4|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_df = df.select([\"review_text\",\"num_rating\"])\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "8BTqDdJniwwG",
    "outputId": "ab80cba5-933c-4f7e-e8bf-573b4f074b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-------------+\n",
      "|label|      date|         review_text|review_length|\n",
      "+-----+----------+--------------------+-------------+\n",
      "|    5|11/25/2016|1 check-in Love l...|          542|\n",
      "|    4| 12/2/2016|Listed in Date Ni...|          279|\n",
      "|    4|11/30/2016|1 check-in Listed...|         1240|\n",
      "|    2|11/25/2016|Very cool vibe! G...|          364|\n",
      "|    4| 12/3/2016|1 check-in They a...|          629|\n",
      "|    4|11/20/2016|1 check-in Very c...|          999|\n",
      "|    4|10/27/2016|2 check-ins Liste...|         1326|\n",
      "|    5| 11/2/2016|2 check-ins Love ...|         1780|\n",
      "|    3|10/25/2016|1 check-in Ok let...|         1805|\n",
      "|    5|11/10/2016|3 check-ins This ...|          725|\n",
      "|    4|10/22/2016|1 check-in Listed...|         1669|\n",
      "|    3|11/20/2016|The store has A+ ...|          509|\n",
      "|    3|11/17/2016|1 check-in Listed...|          835|\n",
      "|    5| 12/5/2016|This is such a cu...|          152|\n",
      "|    5|11/13/2016|Beautiful eccentr...|          378|\n",
      "|    5| 11/9/2016|1 check-in Listed...|         1452|\n",
      "|    5| 11/6/2016|Really love the v...|          395|\n",
      "|    4|10/25/2016|1 check-in Check ...|          778|\n",
      "|    4|10/15/2016|1 check-in Note: ...|          843|\n",
      "|    4| 12/1/2016|So much aesthetic...|          215|\n",
      "+-----+----------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, length\n",
    "review_df = df.withColumn(\"date\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+\", 0))\\\n",
    "      .withColumn(\"review_text\", regexp_extract(\"review_text\", \"\\d+/\\d+/\\d+(?:\\s)(.*)\", 1))\\\n",
    "      .withColumnRenamed(\"num_rating\", \"label\")\\\n",
    "      .select([\"label\", \"date\", \"review_text\"])\n",
    "review_df = review_df.withColumn('review_length', length(review_df['review_text'])).dropna()\n",
    "review_df.cache()\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nRtLVc7i8gK"
   },
   "source": [
    "## Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPFN7XcGiwtP"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "# Create all the features to the data set\n",
    "tokenizer = Tokenizer(inputCol=\"review_text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxsBBQRiiwk-"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'review_length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQ6f6eXfjDfD"
   },
   "outputs": [],
   "source": [
    "# Create and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_ZkNHtAjGUS"
   },
   "source": [
    "## Transform DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fbq2d16jjDcQ"
   },
   "outputs": [],
   "source": [
    "# Fit and transform the pipeline\n",
    "cleaner = data_prep_pipeline.fit(review_df)\n",
    "cleaned = cleaner.transform(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "iAIOltOojKal",
    "outputId": "b84e4249-ae5d-4b64-decd-04e85e4cf9b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    5|(262145,[9639,991...|\n",
      "|    4|(262145,[512,1588...|\n",
      "|    4|(262145,[3578,963...|\n",
      "|    2|(262145,[9639,157...|\n",
      "|    4|(262145,[3294,736...|\n",
      "|    4|(262145,[14,8443,...|\n",
      "|    4|(262145,[14,604,3...|\n",
      "|    5|(262145,[14,4543,...|\n",
      "|    3|(262145,[3890,392...|\n",
      "|    5|(262145,[991,2437...|\n",
      "|    4|(262145,[14,326,3...|\n",
      "|    3|(262145,[6922,736...|\n",
      "|    3|(262145,[6922,963...|\n",
      "|    5|(262145,[4081,158...|\n",
      "|    5|(262145,[1076,199...|\n",
      "|    5|(262145,[14,329,1...|\n",
      "|    5|(262145,[14,1998,...|\n",
      "|    4|(262145,[14,5281,...|\n",
      "|    4|(262145,[7388,963...|\n",
      "|    4|(262145,[9639,158...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show label of ham spame and resulting features\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S37P7oA2jMF9"
   },
   "source": [
    "## Run NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_KHNZkqjN-Z"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "eSO42Oc9jPRV",
    "outputId": "7f41cb6a-6cac-4b51-ccb4-b75e19416b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|     date|         review_text|review_length|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|    1|1/10/2015|1 check-in I just...|         1444|[1, check-in, i, ...|[1, check-in, edi...|(262144,[14,2326,...|(262144,[14,2326,...|(262145,[14,2326,...|[-8530.8523111699...|[5.18392012015807...|       4.0|\n",
      "|    1|1/14/2016|Worst brownie I h...|          103|[worst, brownie, ...|[worst, brownie, ...|(262144,[9639,244...|(262144,[9639,244...|(262145,[9639,244...|[-871.82807074224...|[2.00505882381113...|       3.0|\n",
      "|    1|1/19/2016|Its good place to...|          440|[its, good, place...|[good, place, stu...|(262144,[14,9639,...|(262144,[14,9639,...|(262145,[14,9639,...|[-3113.7191459700...|[1.31283836251754...|       3.0|\n",
      "|    1|1/28/2014|Beware of them ti...|           61|[beware, of, them...|[beware, tipping,...|(262144,[9639,341...|(262144,[9639,341...|(262145,[9639,341...|[-552.67910884004...|[2.43672671168775...|       3.0|\n",
      "|    1| 1/9/2016|Thoroughly disapp...|          358|[thoroughly, disa...|[thoroughly, disa...|(262144,[9639,134...|(262144,[9639,134...|(262145,[9639,134...|[-2222.6114818134...|[3.08210704244631...|       3.0|\n",
      "+-----+---------+--------------------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tik9-ZskjPvO"
   },
   "source": [
    "## Predict accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NuFyog8-jQCQ",
    "outputId": "65515fea-6303-4db1-d459-d823d9c5608f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting reviews was: 0.141092\n"
     ]
    }
   ],
   "source": [
    "# Use the Class Evaluator for a cleaner description\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vRR-utfj1yj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cloud_etl_nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
