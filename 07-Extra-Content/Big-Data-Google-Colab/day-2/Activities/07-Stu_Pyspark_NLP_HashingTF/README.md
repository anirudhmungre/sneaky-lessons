# PySpark NLP TD-IDF with HashingTF

## Instructions

* Read in the file and store in a dataframe.

* Tokenize the dataframe then remove any stop words.

* Hash the term frequencies and store with the output into a new dataframe.

* Fit the dataframe with the inverse document frequency.

## Bonus**

* Use custom words with the  `StopWordsRemover` to take things out like the "@VirginAirline" variations.
